{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14774,"databundleVersionId":875431,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":10515296,"sourceType":"datasetVersion","datasetId":6508726}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ===============================================================\n# Multi-Class DR Classification using Fuzzy SVM\n# Dataset: Folder-based (train/0â€“4, test/0â€“4)\n# ===============================================================\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.svm import SVC\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# ==============================================\n# âœ… Step 1: Load images from train/test subfolders (0â€“4)\n# ==============================================\ntrain_dir = \"/kaggle/input/diabetic-retinopathy-dataset/training_data_set/training_data_set\"   # ğŸ”¹ change path\ntest_dir  = \"/kaggle/input/diabetic-retinopathy-dataset/testing_dataset/testing_dataset\"    # ğŸ”¹ change path\n\ndef load_dataset(base_dir):\n    image_paths = []\n    labels = []\n    for label in sorted(os.listdir(base_dir)):\n        class_folder = os.path.join(base_dir, label)\n        if os.path.isdir(class_folder):\n            for file in os.listdir(class_folder):\n                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                    image_paths.append(os.path.join(class_folder, file))\n                    labels.append(int(label))\n    return image_paths, labels\n\ntrain_image_paths, y_train = load_dataset(train_dir)\ntest_image_paths, y_test = load_dataset(test_dir)\n\nprint(f\"âœ… Train images: {len(train_image_paths)} | Test images: {len(test_image_paths)}\")\n\n# ==============================================\n# âœ… Step 2: Load and preprocess all images\n# ==============================================\ndef load_images(image_paths, target_size=(224, 224)):\n    images = []\n    for path in tqdm(image_paths, desc=\"Loading images\"):\n        img = image.load_img(path, target_size=target_size)\n        img_array = image.img_to_array(img)\n        images.append(preprocess_input(img_array))\n    return np.array(images)\n\nX_train_images = load_images(train_image_paths)\nX_test_images = load_images(test_image_paths)\n\nprint(\"âœ… Image data prepared successfully!\")\nprint(\"Train shape:\", X_train_images.shape)\nprint(\"Test shape :\", X_test_images.shape)\nprint(\"Labels     :\", np.unique(y_train))\n\n# ==============================================\n# âœ… Step 3: Feature Extraction (EfficientNetB0)\n# ==============================================\ntry:\n    print(\"âš™ï¸ Extracting features using EfficientNetB0 (ImageNet weights)...\")\n    base_model = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg')\nexcept Exception:\n    print(\"âš ï¸ ImageNet weights unavailable, switching to random init.\")\n    base_model = EfficientNetB0(weights=None, include_top=False, pooling='avg')\n\nfeatures_train = base_model.predict(X_train_images, batch_size=16, verbose=1)\nfeatures_test = base_model.predict(X_test_images, batch_size=16, verbose=1)\n\nnp.save(\"/kaggle/working/features_train.npy\", features_train)\nnp.save(\"/kaggle/working/features_test.npy\", features_test)\nnp.save(\"/kaggle/working/y_train.npy\", y_train)\nnp.save(\"/kaggle/working/y_test.npy\", y_test)\nprint(\"âœ… Features extracted & saved!\")\n\n# ==============================================\n# âœ… Step 4: Standardization\n# ==============================================\nscaler = StandardScaler()\nX_train = scaler.fit_transform(features_train)\nX_test = scaler.transform(features_test)\n\n# ==============================================\n# âœ… Step 5: Class Weights (Handle Imbalance)\n# ==============================================\nclass_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = dict(zip(np.unique(y_train), class_weights))\nprint(\"Computed class weights:\", class_weight_dict)\n\n# ==============================================\n# âœ… Step 8: Fuzzy SVM (Enhanced)\n# ==============================================\nprint(\"\\nâš™ï¸ Computing fuzzy memberships for Fuzzy SVM...\")\nfuzzy_memberships = np.zeros_like(y_train, dtype=float)\nfor cls in np.unique(y_train):\n    cls_idx = np.where(y_train == cls)[0]\n    cls_mean = np.mean(X_train[cls_idx], axis=0)\n    distances = np.linalg.norm(X_train[cls_idx] - cls_mean, axis=1)\n    fuzzy_memberships[cls_idx] = 1 / (1 + distances)\n\n# Normalize fuzzy memberships\nfuzzy_memberships = fuzzy_memberships / np.max(fuzzy_memberships)\n\nprint(\"\\n===== Fuzzy SVM Classifier =====\")\nsvm_fuzzy = SVC(kernel='rbf', C=5, gamma='scale', probability=True)\nsvm_fuzzy.fit(X_train, y_train, sample_weight=fuzzy_memberships)\ny_pred_fuzzy = svm_fuzzy.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_fuzzy))\nprint(classification_report(y_test, y_pred_fuzzy))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_fuzzy))\n\n# ==============================================\n# âœ… Step 9: Summary\n# ==============================================\nprint(\"\\n========== MODEL PERFORMANCE SUMMARY ==========\")\nprint(f\"Fuzzy SVM   : {accuracy_score(y_test, y_pred_fuzzy):.4f}\")\n\nprint(\"\\nâœ… All results saved in /kaggle/working/\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:32:07.503299Z","iopub.execute_input":"2025-11-06T08:32:07.503604Z","iopub.status.idle":"2025-11-06T08:36:15.143219Z","shell.execute_reply.started":"2025-11-06T08:32:07.503578Z","shell.execute_reply":"2025-11-06T08:36:15.141973Z"}},"outputs":[{"name":"stderr","text":"2025-11-06 08:32:14.267613: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762417934.854623      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762417935.009870      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"âœ… Train images: 2500 | Test images: 496\n","output_type":"stream"},{"name":"stderr","text":"Loading images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2500/2500 [00:26<00:00, 92.84it/s] \nLoading images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 496/496 [00:05<00:00, 96.21it/s] \n","output_type":"stream"},{"name":"stdout","text":"âœ… Image data prepared successfully!\nTrain shape: (2500, 224, 224, 3)\nTest shape : (496, 224, 224, 3)\nLabels     : [0 1 2 3 4]\nâš™ï¸ Extracting features using EfficientNetB0 (ImageNet weights)...\n","output_type":"stream"},{"name":"stderr","text":"2025-11-06 08:33:09.948343: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 842ms/step\n\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 643ms/step\nâœ… Features extracted & saved!\nComputed class weights: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0}\n\nâš™ï¸ Computing fuzzy memberships for Fuzzy SVM...\n\n===== Fuzzy SVM Classifier =====\nAccuracy: 0.9657258064516129\n              precision    recall  f1-score   support\n\n           0       0.88      1.00      0.93       100\n           1       0.98      0.86      0.91       100\n           2       0.99      1.00      1.00       100\n           3       1.00      0.98      0.99        96\n           4       1.00      0.99      0.99       100\n\n    accuracy                           0.97       496\n   macro avg       0.97      0.97      0.97       496\nweighted avg       0.97      0.97      0.97       496\n\nConfusion Matrix:\n [[100   0   0   0   0]\n [ 14  86   0   0   0]\n [  0   0 100   0   0]\n [  0   2   0  94   0]\n [  0   0   1   0  99]]\n\n========== MODEL PERFORMANCE SUMMARY ==========\nFuzzy SVM   : 0.9657\n\nâœ… All results saved in /kaggle/working/\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import joblib\n\njoblib.dump(svm_fuzzy, \"fuzzy_svm_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:37:43.175310Z","iopub.execute_input":"2025-11-06T08:37:43.175980Z","iopub.status.idle":"2025-11-06T08:37:43.242169Z","shell.execute_reply.started":"2025-11-06T08:37:43.175934Z","shell.execute_reply":"2025-11-06T08:37:43.240793Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['scaler.pkl']"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# ===============================================================\n# Gradio Interface for Multi-Class DR Classification\n# Using: Fuzzy SVM + EfficientNetB0 features\n# ===============================================================\n\nimport gradio as gr\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\nfrom sklearn.preprocessing import StandardScaler\n\n# -------------------------\n# Load models and scalers\n# -------------------------\nimport joblib\n\n# Load saved models (make sure to save them after training)\nsvm_fuzzy = joblib.load(\"/kaggle/working/fuzzy_svm_model.pkl\")\nscaler = joblib.load(\"/kaggle/working/scaler.pkl\")\n\n# Load feature extractor\nbase_model = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg')\n\n# Class names\nclass_names = ['0', '1', '2', '3', '4']\n\n# -------------------------\n# Prediction function\n# -------------------------\ndef predict_dr(img):\n    # Preprocess image\n    img = img.resize((224, 224))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = preprocess_input(img_array)\n    \n    # Extract features\n    features = base_model.predict(img_array)\n    features_scaled = scaler.transform(features)\n    \n    # Predict with all models\n    fuzzy_pred = svm_fuzzy.predict(features_scaled)[0]\n    fuzzy_conf = svm_fuzzy.predict_proba(features_scaled)[0]\n    \n    # Prepare results\n    results = {\n        \"Fuzzy SVM Prediction\": fuzzy_pred,\n        \"Fuzzy SVM Confidence\": {class_names[i]: float(fuzzy_conf[i]) for i in range(5)}\n    }\n    \n    return results\n\n# -------------------------\n# Gradio Interface\n# -------------------------\ninterface = gr.Interface(\n    fn=predict_dr,\n    inputs=gr.Image(type=\"pil\"),\n    outputs=gr.JSON(),\n    title=\"Diabetic Retinopathy Multi-Class Prediction\",\n    description=\"Upload a retinal fundus image and get predictions & confidence from Fuzzy SVM models.\"\n)\n\ninterface.launch()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:38:01.923691Z","iopub.execute_input":"2025-11-06T08:38:01.924007Z","iopub.status.idle":"2025-11-06T08:38:11.385650Z","shell.execute_reply.started":"2025-11-06T08:38:01.923983Z","shell.execute_reply":"2025-11-06T08:38:11.384493Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\nIt looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://1752c6c57745d92606.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://1752c6c57745d92606.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n","output_type":"stream"}],"execution_count":3}]}